{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## While evaluating (testing) your algorithms, you should not consider images of your current query identity taken from the same camera. For example, when you create ranklist for the first query image (index 22, label 3, camera 1, name \"1_003_1_02.png\"), you should not include images with indexes 21, 23, 24 in this ranking list, as these are images of the same person (label 3) captured by the camera with index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "#contains indexes of images that can be used for training and validation (Training Validating)   (7368,) 7368 images  (7-10) per person\n",
    "train_idxs = loadmat('./PR_data/cuhk03_new_protocol_config_labeled.mat')['train_idx'].flatten()\n",
    "\n",
    "#specifies whether image was taken from camera 1 or camera 2.    \n",
    "camId = loadmat('./PR_data/cuhk03_new_protocol_config_labeled.mat')['camId'].flatten()\n",
    "\n",
    "# specifies correspondences between names of files in images_cuhk03 and their indexes\n",
    "filelist = loadmat('./PR_data/cuhk03_new_protocol_config_labeled.mat')['filelist'].flatten()\n",
    "\n",
    "#specifies indexes of the part of the dataset from which you compose your ranklists during testing phase (Testing)\n",
    "gallery_idx = loadmat('./PR_data/cuhk03_new_protocol_config_labeled.mat')['gallery_idx'].flatten()\n",
    "\n",
    "#contains ground truths for each image                                                           (14096,) 对应着train_idxs的image label\n",
    "labels = loadmat('./PR_data/cuhk03_new_protocol_config_labeled.mat')['labels'].flatten()\n",
    "\n",
    "#contains indexes of query images (Testing)\n",
    "query_idx = loadmat('./PR_data/cuhk03_new_protocol_config_labeled.mat')['query_idx'].flatten()\n",
    "\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7368,)\n"
     ]
    }
   ],
   "source": [
    "print(train_idxs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import JSON file (14096 x 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "with open('feature_data.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "    \n",
    "feature = np.asarray(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Testing & Validating set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = []\n",
    "lbl_train = []\n",
    "\n",
    "for i in train_idxs:\n",
    "    fea_train.append(feature[i-1])\n",
    "    lbl_train.append(labels[i-1])\n",
    "\n",
    "fea_train = np.asarray(fea_train)\n",
    "lbl_train = np.asarray(lbl_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_feature = []\n",
    "query_lbl = []\n",
    "query_camid = []\n",
    "\n",
    "for i in query_idx:\n",
    "    query_feature.append(feature[i-1])\n",
    "    query_lbl.append(labels[i-1])\n",
    "    query_camid.append(camId[i-1])\n",
    "\n",
    "query_feature = np.asarray(query_feature)\n",
    "query_lbl = np.asarray(query_lbl)\n",
    "query_camid = np.asarray(query_camid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_feature = []\n",
    "gallery_lbl = []\n",
    "gallery_camid = []\n",
    "\n",
    "for i in gallery_idx:\n",
    "    gallery_feature.append(feature[i-1])\n",
    "    gallery_lbl.append(labels[i-1])\n",
    "    gallery_camid.append(camId[i-1])\n",
    "\n",
    "gallery_feature = np.asarray(gallery_feature)\n",
    "gallery_lbl = np.asarray(gallery_lbl)\n",
    "gallery_camid = np.asarray(gallery_camid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set with Validation removed: (6404, 2049)\n",
      "Validation Set: (964, 2049) ( Has an extra row due to np.zeros )\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "train_unique_labels = np.unique(lbl_train)\n",
    "\n",
    "# pick 100 of people and move all pictures of those people to your validation set\n",
    "shuffle_lbl = shuffle(train_unique_labels)[:100] \n",
    "\n",
    "val = np.zeros((1,2049))\n",
    "train = np.vstack((fea_train.T, lbl_train)).T\n",
    "\n",
    "for identity in tqdm( shuffle_lbl ):\n",
    "    #Select validation set from training data\n",
    "    validation = train[ np.where(train[:,-1]==identity)]\n",
    "    \n",
    "    val = np.vstack( ( val, validation ) )\n",
    "    \n",
    "    train = train[ np.where( train[ :, -1 ] != identity )]\n",
    "val = np.delete(val, (0), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Margin Nearest Neighbor (LMNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\metric_learn-0.4.0-py3.7.egg\\metric_learn\\lmnn.py:62: UserWarning: use_pca does nothing for the python_LMNN implementation\n",
      "  warnings.warn('use_pca does nothing for the python_LMNN implementation')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "python_LMNN(convergence_tol=0.001, k=5, learn_rate=1e-06, max_iter=1000,\n",
       "      min_iter=50, regularization=0.5, use_pca=True, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metric_learn import LMNN\n",
    "import time\n",
    "ts = time.time()\n",
    "X = train[:,:2048]\n",
    "y = train[:,-1]\n",
    "\n",
    "lmnn = LMNN(k=5, learn_rate=1e-6)\n",
    "lmnn.fit(X, y)\n",
    "te = time.time()\n",
    "print('Time: %d s'%te-ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 1400)\n",
      "(2048, 5328)\n"
     ]
    }
   ],
   "source": [
    "q_transform = lmnn.transform(query_feature)\n",
    "g_transform = lmnn.transform(gallery_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 2048)\n",
      "(1400, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(query_feature.shape)\n",
    "print(q_transform.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine lbl and feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = q_transform.T\n",
    "g = g_transform.T\n",
    "#feature, camid, lbl\n",
    "#0:2047 2048     2049\n",
    "q_combine = (np.vstack((q,query_camid,query_lbl))).T\n",
    "\n",
    "#feature, camid, lbl\n",
    "\n",
    "g_combine = (np.vstack( ( g, gallery_camid, gallery_lbl ))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 1400)\n",
      "(1400,)\n",
      "(1400,)\n",
      "(2050, 1400)\n",
      "(2048, 5328)\n",
      "(5328,)\n",
      "(5328,)\n",
      "(5328, 2050)\n"
     ]
    }
   ],
   "source": [
    "print(q.shape)\n",
    "print(query_camid.shape)\n",
    "print(query_lbl.shape)\n",
    "print(q_combine.T.shape)\n",
    "\n",
    "print(g.shape)\n",
    "print(gallery_camid.shape)\n",
    "print(gallery_lbl.shape)\n",
    "print(g_combine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7368,)\n",
      "(6404, 2049)\n",
      "(array([6394, 6395, 6396, 6397, 6398, 6399, 6400, 6401, 6402, 6403],\n",
      "      dtype=int64), array([2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(lbl_train.shape)\n",
    "print(train.shape)\n",
    "\n",
    "print(np.where(train == 1467))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:23<00:00, 58.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "X_train = g_combine[:,:-2]\n",
    "y_train = g_combine[:,-1]\n",
    "classifier = NearestNeighbors(n_neighbors=20, metric = 'euclidean')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "query_rank_list_20 = []\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in tqdm(range(q_combine.shape[0])):\n",
    "    \n",
    "    query_lbl = q_combine[i,-1].astype(int)\n",
    "    \n",
    "    \n",
    "    X_test = q_combine[i,:-2].reshape(1,-1)\n",
    "    dist, index = classifier.kneighbors(X_test)\n",
    "    index = index.flatten()\n",
    "    ii = 0\n",
    "    rank_list = []\n",
    "    for j in index:\n",
    "        if len(rank_list) < 15:\n",
    "            if g_combine[j,-1] !=  q_combine[i,-1] or g_combine[j,-2] !=  q_combine[i,-2]:\n",
    "                rank_list.append(g_combine[j,-1].astype(int) == query_lbl)\n",
    "    query_rank_list_20.append(rank_list)\n",
    "\n",
    "query_rank_list_20 = np.asarray(query_rank_list_20)\n",
    "np.savetxt( 'lmnn_ranklist.csv', query_rank_list_20, delimiter= ',' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP():\n",
    "    average_precision=[]\n",
    "    ranklist = np.loadtxt(open(\"lmnn_ranklist.csv\", \"rb\"), delimiter=\",\")\n",
    "    for i in range(len(ranklist)):\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        precisions=[]\n",
    "        s=sum(ranklist[i,:])\n",
    "        for j in range(1,ranklist.shape[1]):\n",
    "            precision.append(sum(ranklist[i,:j]/j))\n",
    "            recall.append(sum(ranklist[i,:j]/s))\n",
    "            if recall[j-1] == 1:\n",
    "                  break\n",
    "\n",
    "        u=[]\n",
    "        indices=[]\n",
    "        recall=np.array(recall)\n",
    "        precision=np.array(precision)\n",
    "        u, indices=np.unique(recall,return_index=True)\n",
    "\n",
    "        precisions=precision[indices]\n",
    "        precisions=precisions[precisions!=0]\n",
    "        average_precision.append(np.mean(precisions))\n",
    "    average_precision = np.nan_to_num(average_precision)\n",
    "    print('mAP :{}'.format(np.mean(average_precision[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 1: 45.57142857142858%\n",
      "rank 5: 66.0%\n",
      "rank 10: 74.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP :0.45730569317506414\n"
     ]
    }
   ],
   "source": [
    "rank1 = query_rank_list_20.T[0].T\n",
    "rank5  = query_rank_list_20.T[:5].T\n",
    "rank10 = query_rank_list_20.T[:10].T\n",
    "\n",
    "cmc1  = rank1\n",
    "cmc5  = np.sum(rank5, axis = 1) > 0\n",
    "cmc10 = np.sum(rank10, axis = 1) > 0\n",
    "\n",
    "print( 'rank 1: {}%'.format(np.sum(cmc1)/cmc1.shape[0]* 100))\n",
    "print( 'rank 5: {}%'.format(np.sum(cmc5)/cmc5.shape[0]* 100 ))\n",
    "print( 'rank 10: {}%'.format(np.sum(cmc10)/cmc10.shape[0]*100))\n",
    "\n",
    "mAP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:16<00:00, 84.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "X_train = g_combine[:,:-2]\n",
    "y_train = g_combine[:,-1]\n",
    "classifier = NearestNeighbors(n_neighbors=20, metric = 'chebyshev')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "query_rank_list_20 = []\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in tqdm(range(q_combine.shape[0])):\n",
    "    \n",
    "    query_lbl = q_combine[i,-1].astype(int)\n",
    "    \n",
    "    \n",
    "    X_test = q_combine[i,:-2].reshape(1,-1)\n",
    "    dist, index = classifier.kneighbors(X_test)\n",
    "    index = index.flatten()\n",
    "    ii = 0\n",
    "    rank_list = []\n",
    "    for j in index:\n",
    "        if len(rank_list) < 15:\n",
    "            if g_combine[j,-1] !=  q_combine[i,-1] or g_combine[j,-2] !=  q_combine[i,-2]:\n",
    "                rank_list.append(g_combine[j,-1].astype(int) == query_lbl)\n",
    "    query_rank_list_20.append(rank_list)\n",
    "\n",
    "query_rank_list_20 = np.asarray(query_rank_list_20)\n",
    "np.savetxt( 'lmnn_chebyshev_ranklist.csv', query_rank_list_20, delimiter= ',' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP():\n",
    "    average_precision=[]\n",
    "    ranklist = np.loadtxt(open(\"lmnn_chebyshev_ranklist.csv\", \"rb\"), delimiter=\",\")\n",
    "    for i in range(len(ranklist)):\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        precisions=[]\n",
    "        s=sum(ranklist[i,:])\n",
    "        for j in range(1,ranklist.shape[1]):\n",
    "            precision.append(sum(ranklist[i,:j]/j))\n",
    "            recall.append(sum(ranklist[i,:j]/s))\n",
    "            if recall[j-1] == 1:\n",
    "                  break\n",
    "\n",
    "        u=[]\n",
    "        indices=[]\n",
    "        recall=np.array(recall)\n",
    "        precision=np.array(precision)\n",
    "        u, indices=np.unique(recall,return_index=True)\n",
    "\n",
    "        precisions=precision[indices]\n",
    "        precisions=precisions[precisions!=0]\n",
    "        average_precision.append(np.mean(precisions))\n",
    "    average_precision = np.nan_to_num(average_precision)\n",
    "    print('mAP :{}'.format(np.mean(average_precision[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 1: 32.0%\n",
      "rank 5: 50.857142857142854%\n",
      "rank 10: 57.92857142857143%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP :0.3538241098641385\n"
     ]
    }
   ],
   "source": [
    "rank1 = query_rank_list_20.T[0].T\n",
    "rank5  = query_rank_list_20.T[:5].T\n",
    "rank10 = query_rank_list_20.T[:10].T\n",
    "\n",
    "cmc1  = rank1\n",
    "cmc5  = np.sum(rank5, axis = 1) > 0\n",
    "cmc10 = np.sum(rank10, axis = 1) > 0\n",
    "\n",
    "print( 'rank 1: {}%'.format(np.sum(cmc1)/cmc1.shape[0]* 100))\n",
    "print( 'rank 5: {}%'.format(np.sum(cmc5)/cmc5.shape[0]* 100 ))\n",
    "print( 'rank 10: {}%'.format(np.sum(cmc10)/cmc10.shape[0]*100))\n",
    "\n",
    "mAP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:19<00:00, 72.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "X_train = g_combine[:,:-2]\n",
    "y_train = g_combine[:,-1]\n",
    "classifier = NearestNeighbors(n_neighbors=20, metric = 'manhattan')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "query_rank_list_20 = []\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in tqdm(range(q_combine.shape[0])):\n",
    "    \n",
    "    query_lbl = q_combine[i,-1].astype(int)\n",
    "    \n",
    "    \n",
    "    X_test = q_combine[i,:-2].reshape(1,-1)\n",
    "    dist, index = classifier.kneighbors(X_test)\n",
    "    index = index.flatten()\n",
    "    ii = 0\n",
    "    rank_list = []\n",
    "    for j in index:\n",
    "        if len(rank_list) < 15:\n",
    "            if g_combine[j,-1] !=  q_combine[i,-1] or g_combine[j,-2] !=  q_combine[i,-2]:\n",
    "                rank_list.append(g_combine[j,-1].astype(int) == query_lbl)\n",
    "    query_rank_list_20.append(rank_list)\n",
    "\n",
    "query_rank_list_20 = np.asarray(query_rank_list_20)\n",
    "np.savetxt( 'lmnn_manhattan_ranklist.csv', query_rank_list_20, delimiter= ',' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP():\n",
    "    average_precision=[]\n",
    "    ranklist = np.loadtxt(open(\"lmnn_manhattan_ranklist.csv\", \"rb\"), delimiter=\",\")\n",
    "    for i in range(len(ranklist)):\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        precisions=[]\n",
    "        s=sum(ranklist[i,:])\n",
    "        for j in range(1,ranklist.shape[1]):\n",
    "            precision.append(sum(ranklist[i,:j]/j))\n",
    "            recall.append(sum(ranklist[i,:j]/s))\n",
    "            if recall[j-1] == 1:\n",
    "                  break\n",
    "\n",
    "        u=[]\n",
    "        indices=[]\n",
    "        recall=np.array(recall)\n",
    "        precision=np.array(precision)\n",
    "        u, indices=np.unique(recall,return_index=True)\n",
    "\n",
    "        precisions=precision[indices]\n",
    "        precisions=precisions[precisions!=0]\n",
    "        average_precision.append(np.mean(precisions))\n",
    "    average_precision = np.nan_to_num(average_precision)\n",
    "    print('mAP :{}'.format(np.mean(average_precision[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 1: 44.642857142857146%\n",
      "rank 5: 65.42857142857143%\n",
      "rank 10: 73.07142857142857%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Program_user\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP :0.47945104957256496\n"
     ]
    }
   ],
   "source": [
    "rank1 = query_rank_list_20.T[0].T\n",
    "rank5  = query_rank_list_20.T[:5].T\n",
    "rank10 = query_rank_list_20.T[:10].T\n",
    "\n",
    "cmc1  = rank1\n",
    "cmc5  = np.sum(rank5, axis = 1) > 0\n",
    "cmc10 = np.sum(rank10, axis = 1) > 0\n",
    "\n",
    "print( 'rank 1: {}%'.format(np.sum(cmc1)/cmc1.shape[0]* 100))\n",
    "print( 'rank 5: {}%'.format(np.sum(cmc5)/cmc5.shape[0]* 100 ))\n",
    "print( 'rank 10: {}%'.format(np.sum(cmc10)/cmc10.shape[0]*100))\n",
    "\n",
    "mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
